{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5e37fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Downloading bertopic-0.14.1-py2.py3-none-any.whl (120 kB)\n",
      "     -------------------------------------- 120.7/120.7 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from bertopic) (5.9.0)\n",
      "Collecting hdbscan>=0.8.29\n",
      "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
      "     ---------------------------------------- 5.2/5.2 MB 8.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from bertopic) (1.4.4)\n",
      "Collecting sentence-transformers>=0.4.1\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from bertopic) (1.0.2)\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "     ---------------------------------------- 88.2/88.2 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from bertopic) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from bertopic) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.9.1)\n",
      "Requirement already satisfied: cython>=0.27 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (0.29.32)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 12.4 MB/s eta 0:00:00\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "     -------------------------------------- 172.4/172.4 MB 6.7 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-win_amd64.whl (977 kB)\n",
      "     ------------------------------------- 977.6/977.6 kB 12.4 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     ------------------------------------- 224.5/224.5 kB 13.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.5)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.55.1)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 12.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.7.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.38.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (63.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.11.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.7.9)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 13.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aguil\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.2.1)\n",
      "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=da8845399c292fade05e3d4a751684430d6ad8b6bf283d86c4af1df8137a24b8\n",
      "  Stored in directory: c:\\users\\aguil\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "  Building wheel for umap-learn (setup.py): started\n",
      "  Building wheel for umap-learn (setup.py): finished with status 'done'\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82814 sha256=4f1ed6d22ac3ab065183a583a5296df79925699bef68f4ce6340877383d49b8e\n",
      "  Stored in directory: c:\\users\\aguil\\appdata\\local\\pip\\cache\\wheels\\f4\\3e\\1c\\596d0a463d17475af648688443fa4846fef624d1390339e7e9\n",
      "  Building wheel for pynndescent (setup.py): started\n",
      "  Building wheel for pynndescent (setup.py): finished with status 'done'\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=bb887850c0669ecd6a9cc45c93ff05ffcf437675396b80543990642bba28bb7a\n",
      "  Stored in directory: c:\\users\\aguil\\appdata\\local\\pip\\cache\\wheels\\12\\f9\\4d\\ec5ad1c823c710fcc4473669fdcffc8891f4bc398c841af22e\n",
      "Successfully built sentence-transformers umap-learn pynndescent\n",
      "Failed to build hdbscan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for hdbscan (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [40 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\hdbscan_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\plots.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\prediction.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\robust_single_linkage_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\validity.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_hdbscan.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_prediction_utils.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_rsl.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  running build_ext\n",
      "  cythoning hdbscan/_hdbscan_tree.pyx to hdbscan\\_hdbscan_tree.c\n",
      "  C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-build-env-bu0mohxg\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-install-mxycdn3f\\hdbscan_5eca82aea18645a48753c84b1370a753\\hdbscan\\_hdbscan_tree.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_linkage.pyx to hdbscan\\_hdbscan_linkage.c\n",
      "  C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-build-env-bu0mohxg\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-install-mxycdn3f\\hdbscan_5eca82aea18645a48753c84b1370a753\\hdbscan\\_hdbscan_linkage.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_boruvka.pyx to hdbscan\\_hdbscan_boruvka.c\n",
      "  C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-build-env-bu0mohxg\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-install-mxycdn3f\\hdbscan_5eca82aea18645a48753c84b1370a753\\hdbscan\\_hdbscan_boruvka.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_reachability.pyx to hdbscan\\_hdbscan_reachability.c\n",
      "  C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-build-env-bu0mohxg\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-install-mxycdn3f\\hdbscan_5eca82aea18645a48753c84b1370a753\\hdbscan\\_hdbscan_reachability.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_prediction_utils.pyx to hdbscan\\_prediction_utils.c\n",
      "  C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-build-env-bu0mohxg\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-install-mxycdn3f\\hdbscan_5eca82aea18645a48753c84b1370a753\\hdbscan\\_prediction_utils.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/dist_metrics.pyx to hdbscan\\dist_metrics.c\n",
      "  C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-build-env-bu0mohxg\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\aguil\\AppData\\Local\\Temp\\pip-install-mxycdn3f\\hdbscan_5eca82aea18645a48753c84b1370a753\\hdbscan\\dist_metrics.pxd\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'hdbscan._hdbscan_tree' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hdbscan\n",
      "ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8afafe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household\n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household\n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics\n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories\n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Ecommerce_data.csv\")\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping the lable column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6cae4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>Marvel Physics MCQ's for MHT - CET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>Internet Download Manager | Lifetime License |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>Sadhubela's Handcrafted Iron Degchi Handi Pot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>Audio-Technica AT-LP60 Automatic Belt Driven D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>LG GH24NSB0 DVD Writer 24X SATA Internal OEM P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text\n",
       "0      Urban Ladder Eisner Low Back Study-Office Comp...\n",
       "1      Contrast living Wooden Decorative Box,Painted ...\n",
       "2      IO Crest SY-PCI40010 PCI RAID Host Controller ...\n",
       "3      ISAKAA Baby Socks from Just Born to 8 Years- P...\n",
       "4      Indira Designer Women's Art Mysore Silk Saree ...\n",
       "...                                                  ...\n",
       "23995                 Marvel Physics MCQ's for MHT - CET\n",
       "23996  Internet Download Manager | Lifetime License |...\n",
       "23997  Sadhubela's Handcrafted Iron Degchi Handi Pot ...\n",
       "23998  Audio-Technica AT-LP60 Automatic Belt Driven D...\n",
       "23999  LG GH24NSB0 DVD Writer 24X SATA Internal OEM P...\n",
       "\n",
       "[24000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= df.drop('label', axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c984ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing NaN (24000 - 23427 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8f3c7e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23422</th>\n",
       "      <td>23995</td>\n",
       "      <td>Marvel Physics MCQ's for MHT - CET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23423</th>\n",
       "      <td>23996</td>\n",
       "      <td>Internet Download Manager | Lifetime License |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23424</th>\n",
       "      <td>23997</td>\n",
       "      <td>Sadhubela's Handcrafted Iron Degchi Handi Pot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23425</th>\n",
       "      <td>23998</td>\n",
       "      <td>Audio-Technica AT-LP60 Automatic Belt Driven D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23426</th>\n",
       "      <td>23999</td>\n",
       "      <td>LG GH24NSB0 DVD Writer 24X SATA Internal OEM P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23427 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               Text\n",
       "0          0  Urban Ladder Eisner Low Back Study-Office Comp...\n",
       "1          1  Contrast living Wooden Decorative Box,Painted ...\n",
       "2          2  IO Crest SY-PCI40010 PCI RAID Host Controller ...\n",
       "3          3  ISAKAA Baby Socks from Just Born to 8 Years- P...\n",
       "4          4  Indira Designer Women's Art Mysore Silk Saree ...\n",
       "...      ...                                                ...\n",
       "23422  23995                 Marvel Physics MCQ's for MHT - CET\n",
       "23423  23996  Internet Download Manager | Lifetime License |...\n",
       "23424  23997  Sadhubela's Handcrafted Iron Degchi Handi Pot ...\n",
       "23425  23998  Audio-Technica AT-LP60 Automatic Belt Driven D...\n",
       "23426  23999  LG GH24NSB0 DVD Writer 24X SATA Internal OEM P...\n",
       "\n",
       "[23427 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= df1 [df1['Text'].str.len()>30].reset_index()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784d574",
   "metadata": {},
   "source": [
    "# CountVectorizer removes stop words in one of the later sets of bear topic\n",
    "# For lower volumes of data stopwords can cause issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30b5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be0fb5f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5900\\3653101154.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21ad7856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (749015844.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\aguil\\AppData\\Local\\Temp\\ipykernel_5900\\749015844.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english”)\u001b[0m\n\u001b[1;37m                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english”)\n",
    "\n",
    "\n",
    "if type(data['Text']) is list:\n",
    "    text = data['Text']\n",
    "else:\n",
    "    text = data['Text'].tolist()\n",
    "    \n",
    "\n",
    "model = BerTopic(\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    language='english', calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = model.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3770a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
